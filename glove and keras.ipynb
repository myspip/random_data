{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myspip/random_data/blob/master/glove%20and%20keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "yl1DNUPPs4qC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "\n",
        "\n",
        "BASE_DIR = ''\n",
        "GLOVE_DIR = os.path.join(BASE_DIR, 'glove.6B')\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1BO2hxK1s7W8",
        "colab_type": "code",
        "outputId": "1f4f4749-16a7-4565-892a-31ad6f27e432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-25 21:14:04--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-03-25 21:14:04--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  3.31MB/s    in 11m 7s  \n",
            "\n",
            "2019-03-25 21:25:11 (1.23 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UekZbY-3s7Z1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VDtUe_bpNjVO",
        "colab_type": "code",
        "outputId": "b256e8ed-1e40-45cd-a889-d93ea38f6b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import gensim\n",
        "# from gensim.models.word2vec import Word2Vec # the word2vec model gensim class\n",
        "# import gzip, shutil\n",
        "\n",
        "# print(gensim.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mi-hwB8Ps4vK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yAvXdfJds4si",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E8GEt3usNn5R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_kZKeTlOhIo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# with gzip.open('GoogleNews-vectors-negative300.bin.gz', 'r') as f_in, open('GoogleNews-vectors-negative300.bin', 'wb') as f_out:\n",
        "#   shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M-oW_LLzObJp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TLuZCeBYN7pk",
        "colab_type": "code",
        "outputId": "18902c14-0fca-48fe-e24c-99b761c92285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# word_vectors = model.wv\n",
        "# MAX_NB_WORDS = len(word_vectors.vocab)\n",
        "# MAX_SEQUENCE_LENGTH = 200"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_EKgG_eZQBA8",
        "colab_type": "code",
        "outputId": "bb5e2a61-982b-45d7-83b9-d04e30994054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# print(\"Number of word vectors: {}\".format(len(word_vectors.vocab)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of word vectors: 3000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4uV4ksx-SaAo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WMs2yWmjUg8o",
        "colab_type": "code",
        "outputId": "602f767e-4830-49c8-82da-7646078a8f3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"https://raw.githubusercontent.com/myspip/random_data/master/Headline/Clean1_TRAIN.csv\")\n",
        "train_data.loc[:, \"Headline\"].replace(re.compile(r'\\b{}\\b'.format(\"company company\"), re.IGNORECASE), \"company\", inplace=True)\n",
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Bad</td>\n",
              "      <td>company thats  lot  recalls  barrons blog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>event alert kinaxis customer company company ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Bad</td>\n",
              "      <td>company  risky   autonomous driving plan  barr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Good</td>\n",
              "      <td>company plans ridehailing service  fleet  driv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Bad</td>\n",
              "      <td>company files k   events f</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id Sentiment                                           Headline\n",
              "0   0       Bad          company thats  lot  recalls  barrons blog\n",
              "1   1   Neutral   event alert kinaxis customer company company ...\n",
              "2   2       Bad  company  risky   autonomous driving plan  barr...\n",
              "3   3      Good  company plans ridehailing service  fleet  driv...\n",
              "4   4       Bad                         company files k   events f"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "E5WO58fKUhD_",
        "colab_type": "code",
        "outputId": "1774d567-9cad-446a-be17-e40509dc77ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(\"https://raw.githubusercontent.com/myspip/random_data/master/Headline/Clean1_TEST.csv\")\n",
        "test_data.loc[:, \"Headline\"].replace(re.compile(r'\\b{}\\b'.format(\"company company\"), re.IGNORECASE), \"company\", inplace=True)\n",
        "test_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Good</td>\n",
              "      <td>building materials producer company raises  sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Good</td>\n",
              "      <td>company plans  asset sales debt reduction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Good</td>\n",
              "      <td>company announces  increase  net income     s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Good</td>\n",
              "      <td>years  opposition mine expansion passes despi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Good</td>\n",
              "      <td>digital platform company go lists  customers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id Sentiment                                           Headline\n",
              "0   0      Good  building materials producer company raises  sa...\n",
              "1   1      Good          company plans  asset sales debt reduction\n",
              "2   2      Good   company announces  increase  net income     s...\n",
              "3   3      Good   years  opposition mine expansion passes despi...\n",
              "4   4      Good       digital platform company go lists  customers"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "1zHvBeMGnoP_",
        "colab_type": "code",
        "outputId": "f45488ba-bddd-405a-b1c4-b707f699668d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_data_list = train_data[\"Headline\"].values\n",
        "label = train_data[\"Sentiment\"].values\n",
        "\n",
        "test_data_list = test_data[\"Headline\"].values\n",
        "test_label = test_data[\"Sentiment\"].values\n",
        "\n",
        "combined_data_list = np.concatenate((train_data_list,test_data_list), axis = 0)\n",
        "len(combined_data_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2147"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "OhpJpPU2ociP",
        "colab_type": "code",
        "outputId": "4ee41463-80de-4536-af80-64e16c256217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "transformed_label = [0 if x == \"Bad\" else (1 if x == \"Good\" else 2) for x in label]\n",
        "test_transformed_label = [0 if x == \"Bad\" else (1 if x == \"Good\" else 2) for x in test_label]\n",
        "transformed_label[0:13]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 2, 0, 1, 0, 0, 0, 0, 2, 2, 2, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "3rnx5gJ8nZvc",
        "colab_type": "code",
        "outputId": "9424af16-8a75-4d4f-9493-170062465dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "MAX_NB_WORDS = 100\n",
        "\n",
        "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(combined_data_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jJjqvDnZpNDn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(train_data_list)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "labels = to_categorical(np.asarray(transfomed_label))\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "x_train = data\n",
        "y_train = labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uo2SkIsypNGD",
        "colab_type": "code",
        "outputId": "721f7dca-e26a-47eb-8127-44d353d1a561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(test_data_list)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "labels = to_categorical(np.asarray(test_transformed_label))\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "x_test = data\n",
        "y_test = labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4578 unique tokens.\n",
            "Shape of data tensor: (241, 200)\n",
            "Shape of label tensor: (241, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2kv3VwYapNI7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7z6JLxIqsCQi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gHU6hTaYsCTB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oR23Jc_QsCOe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6nKRZ-w3b7NZ",
        "colab_type": "code",
        "outputId": "0f49915d-8c05-401a-80af-6fd5b4ce8c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "re.sub(\"[^\\w]\", \" \",  train_data.Headline[1]).split()\n",
        "vocab['event'].count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2999576"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "WDevRw6xUHQT",
        "colab_type": "code",
        "outputId": "c46e49ea-ae9f-4a20-f9ef-37e23f779751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "vocab = word_vectors.vocab\n",
        "sequences = [[vocab[t].count for t in re.sub(\"[^\\w]\", \" \",  headline).split()]\n",
        "             for headline in train_data[\"Headline\"].values]\n",
        "test_sequences = [[vocab[t] for t in re.sub(\"[^\\w]\", \" \",  headline).split()]\n",
        "                  for headline in test_data[\"Headline\"].values]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-640981520fbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m sequences = [[vocab[t].count for t in re.sub(\"[^\\w]\", \" \",  headline).split()]\n\u001b[0;32m----> 4\u001b[0;31m              for headline in train_data[\"Headline\"].values]\n\u001b[0m\u001b[1;32m      5\u001b[0m test_sequences = [[vocab[t] for t in re.sub(\"[^\\w]\", \" \",  headline).split()]\n\u001b[1;32m      6\u001b[0m                   for headline in test_data[\"Headline\"].values]\n",
            "\u001b[0;32m<ipython-input-46-640981520fbd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m sequences = [[vocab[t].count for t in re.sub(\"[^\\w]\", \" \",  headline).split()]\n\u001b[0;32m----> 4\u001b[0;31m              for headline in train_data[\"Headline\"].values]\n\u001b[0m\u001b[1;32m      5\u001b[0m test_sequences = [[vocab[t] for t in re.sub(\"[^\\w]\", \" \",  headline).split()]\n\u001b[1;32m      6\u001b[0m                   for headline in test_data[\"Headline\"].values]\n",
            "\u001b[0;32m<ipython-input-46-640981520fbd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m sequences = [[vocab[t].count for t in re.sub(\"[^\\w]\", \" \",  headline).split()]\n\u001b[0m\u001b[1;32m      4\u001b[0m              for headline in train_data[\"Headline\"].values]\n\u001b[1;32m      5\u001b[0m test_sequences = [[vocab[t] for t in re.sub(\"[^\\w]\", \" \",  headline).split()]\n",
            "\u001b[0;31mKeyError\u001b[0m: 'barrons'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "TnzX4p0KZjvy",
        "colab_type": "code",
        "outputId": "34f488c4-7287-400d-fe6a-2162f600ae27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "word_vectors.vocab[''].count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1319845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "MowhBvalZQXk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pad\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, \n",
        "                     padding=\"pre\", truncating=\"post\")\n",
        "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "y = train_df[list_classes].values\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', y.shape)\n",
        "\n",
        "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"pre\",\n",
        "                          truncating=\"post\")\n",
        "print('Shape of test_data tensor:', test_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "anEdhBv6UHOg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "WV_DIM = 100\n",
        "nb_words = min(MAX_NB_WORDS, len(word_vectors.vocab))\n",
        "# we initialize the matrix with random numbers\n",
        "wv_matrix = (np.random.rand(nb_words, WV_DIM) - 0.5) / 5.0\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_NB_WORDS:\n",
        "        continue\n",
        "    try:\n",
        "        embedding_vector = word_vectors[word]\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        wv_matrix[i] = embedding_vector\n",
        "    except:\n",
        "        pass  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2muCj51gUHMe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "82slnochUHJ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ybMNhOrOUHGE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pd4h9OPISbpE",
        "colab_type": "code",
        "outputId": "5df5fc40-626b-42cc-b164-5c0fb123444b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"/var/log/colab-jupyter.log\", \"r\") as fo:\n",
        "  for line in fo:\n",
        "    print(json.loads(line)['msg'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret\n",
            "google.colab serverextension initialized.\n",
            "Serving notebooks from local directory: /\n",
            "0 active kernels\n",
            "The Jupyter Notebook is running at:\n",
            "http://172.28.0.2:9000/\n",
            "Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
            "Kernel started: f910f69f-f6c3-4929-9bc3-47c4ed2eb019\n",
            "Adapting to protocol v5.1 for kernel f910f69f-f6c3-4929-9bc3-47c4ed2eb019\n",
            "Adapting to protocol v5.1 for kernel f910f69f-f6c3-4929-9bc3-47c4ed2eb019\n",
            "Kernel started: b1c5404a-3825-4f8b-aa5c-56aa8e42eaa5\n",
            "Adapting to protocol v5.1 for kernel b1c5404a-3825-4f8b-aa5c-56aa8e42eaa5\n",
            "tcmalloc: large alloc 3644260352 bytes == 0x117398000 @  0x7ff2083f11e7 0x59213c 0x596936 0x5d6527 0x565cda 0x5a3761 0x5a3a5e 0x4c4364 0x502d6f 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x511eca 0x502d6f 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x501b2e 0x591461 0x59ebbe 0x507c17\n",
            "tcmalloc: large alloc 3600007168 bytes == 0x1f0708000 @  0x7ff2083f3001 0x7ff1fcae6b85 0x7ff1fcb49b43 0x7ff1fcb4ba86 0x7ff1fcbe3868 0x5030d5 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x511eca 0x502d6f 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x501b2e 0x591461 0x59ebbe\n",
            "tcmalloc: large alloc 3600007168 bytes == 0x2c78b0000 @  0x7ff2083f11e7 0x7ff1fcae6a41 0x7ff1fcb49c13 0x7ff1fcb49cda 0x7ff1f7655aee 0x7ff1f76561ef 0x59929b 0x7ff1fcc03620 0x591bde 0x5085f9 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x511eca 0x502d6f 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28\n",
            "KernelRestarter: restarting kernel (1/5), keep random ports\n",
            "WARNING:root:kernel b1c5404a-3825-4f8b-aa5c-56aa8e42eaa5 restarted\n",
            "tcmalloc: large alloc 3600007168 bytes == 0x5316000 @  0x7ff63c000001 0x7ff6306f3b85 0x7ff630756b43 0x7ff630758a86 0x7ff6307f0868 0x5030d5 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x511eca 0x502d6f 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x501b2e 0x591461 0x59ebbe\n",
            "tcmalloc: large alloc 3600007168 bytes == 0xefca6000 @  0x7ff63bffe1e7 0x7ff6306f3a41 0x7ff630756c13 0x7ff630756cda 0x7ff62b262aee 0x7ff62b2631ef 0x59929b 0x7ff630810620 0x591bde 0x5085f9 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x511eca 0x502d6f 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28\n",
            "tcmalloc: large alloc 3600007168 bytes == 0xefca6000 @  0x7ff63bffe1e7 0x7ff6306f3a41 0x7ff630756c13 0x7ff630756cda 0x7ff6308044ed 0x7ff630804e3b 0x7ff6308076c8 0x7ff62b262287 0x7ff62b2631ef 0x59929b 0x7ff63080fae7 0x59b552 0x509289 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x511eca 0x502d6f 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540\n",
            "tcmalloc: large alloc 3600007168 bytes == 0x1c6de8000 @  0x7ff63bffe1e7 0x7ff6306f3a41 0x7ff6307597c0 0x7ff6307eaf02 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x511eca 0x502d6f 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x501b2e 0x591461 0x59ebbe 0x507c17\n",
            "KernelRestarter: restarting kernel (1/5), keep random ports\n",
            "WARNING:root:kernel b1c5404a-3825-4f8b-aa5c-56aa8e42eaa5 restarted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JKuU8YH5TWA5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}